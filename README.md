# Smart Logistics Analytics Platform

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![dbt](https://img.shields.io/badge/dbt-1.0+-orange.svg)](https://www.getdbt.com/)
[![Snowflake](https://img.shields.io/badge/Snowflake-Compatible-blue.svg)](https://www.snowflake.com/)

## Overview

This repository contains a **production-ready ML data product** for logistics analytics, designed specifically for AI engineers to build machine learning models. The platform demonstrates modern data engineering practices through a **hybrid ML-optimized architecture** using **Snowflake + dbt + Fivetran** stack.

## ğŸš€ Quick Start

### **Option 1: Complete Automated Deployment**
```bash
# Clone repository
git clone https://github.com/jhazured/logistics-analytics-platform.git
cd logistics-analytics-platform

# Create .env file with your Snowflake credentials (see .env.example)
cp .env.example .env
# Edit .env with your Snowflake credentials

# Run complete deployment
./deploy.sh
```

### **Option 2: Parameterized SQL Setup**
```bash
# Clone repository
git clone https://github.com/jhazured/logistics-analytics-platform.git
cd logistics-analytics-platform

# Set environment variables for your target database
export SF_ACCOUNT="your-account.snowflakecomputing.com"
export SF_USER="your-username"
export SF_PASSWORD="your-password"
export SF_ROLE="ACCOUNTADMIN"
export SF_WAREHOUSE="COMPUTE_WH_XS"
export SF_DATABASE="LOGISTICS_DW_DEV"  # Can be changed to any database name
export SF_SCHEMA="ANALYTICS"

# Execute parameterized setup scripts
python3 scripts/01_setup/handlers/execute_sql_python.py scripts/01_setup/tasks/01_database_setup.sql
python3 scripts/01_setup/handlers/execute_sql_python.py scripts/01_setup/tasks/02_schema_creation.sql
python3 scripts/01_setup/handlers/execute_sql_python.py scripts/01_setup/tasks/04_user_roles_permissions.sql

# Run dbt models
dbt run --full-refresh --select tag:raw
dbt run --select tag:incremental
```

### **Option 3: Manual dbt Deployment**
```bash
# Clone repository
git clone https://github.com/jhazured/logistics-analytics-platform.git
cd logistics-analytics-platform

# Initial Setup (Full Refresh)
dbt run --full-refresh --select tag:raw

# Incremental Updates (Cost-Optimized)
dbt run --select tag:incremental
```

> **ğŸ’¡ Cost Optimization**: This project uses incremental loading to minimize Fivetran costs by 70-90%. See [docs/07_INCREMENTAL_LOADING_STRATEGY.md](docs/07_INCREMENTAL_LOADING_STRATEGY.md) for details.
> 
> **ğŸš€ New Deployment System**: Use `./deploy.sh` for complete automated deployment with 7-phase orchestration. See [docs/DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) for details.
> 
> **ğŸ”§ Parameterized Configuration**: All SQL scripts and dbt configurations are fully parameterized using environment variables, making it easy to deploy across different environments (dev/staging/prod) without code changes.

## ğŸ“š Documentation

- **[Complete Documentation](docs/00_README.md)** - Comprehensive project documentation
- **[Architecture Overview](docs/01_ARCHITECTURE.md)** - System design and technology stack
- **[Setup Instructions](docs/02_SETUP.md)** - Complete setup and deployment guide
- **[ML/AI Engineer Guide](docs/03_ML_GUIDE.md)** - ML feature engineering and model development
- **[Advanced Features](docs/04_ADVANCED_FEATURES.md)** - Real-time processing and advanced analytics
- **[Monitoring & Alerting](docs/05_MONITORING.md)** - Data quality and performance monitoring
- **[Business Impact & ROI](docs/06_BUSINESS_IMPACT.md)** - Business value and return on investment
- **[Incremental Loading Strategy](docs/07_INCREMENTAL_LOADING_STRATEGY.md)** - Cost optimization guide
- **[File Index](docs/08_INDEX.md)** - Raw GitHub URLs for all project files
- **[Deployment Guide](docs/DEPLOYMENT_GUIDE.md)** - Complete deployment orchestration guide
- **[Data Dictionary](docs/09_DATA_DICTIONARY.md)** - Business definitions and technical specifications
- **[Business Processes](docs/10_BUSINESS_PROCESSES.md)** - Core business processes and procedures
- **[Operational Runbooks](docs/11_OPERATIONAL_RUNBOOKS.md)** - Step-by-step operational procedures
- **[Troubleshooting Guides](docs/12_TROUBLESHOOTING_GUIDES.md)** - Comprehensive troubleshooting procedures

## ğŸ¯ Key Features

- **ML-Optimized Architecture**: Hybrid dbt + Snowflake design for ML training and inference
- **Production ML Models**: Actual trained models for route optimization and predictive maintenance
- **Feature Store**: Centralized ML feature repository with versioning and real-time serving
- **Model Registry**: Complete ML model lifecycle management with performance tracking
- **Real-time ML Serving**: Low-latency feature serving for ML inference workloads
- **Advanced Data Governance**: Automated lineage with business impact analysis
- **Predictive FinOps**: ML-driven cost optimization with automated recommendations
- **Cost Optimization**: 70-90% reduction in Fivetran costs through incremental loading
- **Advanced Analytics**: 22+ analytical views with rolling time windows
- **Enterprise Security**: Role-based access control and data masking
- **CI/CD Pipeline**: Automated testing, deployment, and monitoring
- **Comprehensive Automation**: Data quality monitoring, performance optimization, ML lifecycle management

## ğŸ“Š Business Impact

- **15-20%** reduction in fuel costs through route optimization
- **25%** improvement in delivery time predictability
- **25%** reduction in Snowflake compute costs through optimization
- **30%** faster time-to-insight for business stakeholders
- **70-90%** reduction in Fivetran data processing costs through incremental loading

## ğŸ› ï¸ Tech Stack

- **Data Warehouse**: Snowflake
- **Data Transformation**: dbt Core 1.6+
- **Data Integration**: Fivetran
- **ML/AI**: Snowflake ML, Feature Store, Model Registry
- **Orchestration**: GitHub Actions
- **Monitoring**: Custom Python scripts
- **Security**: Snowflake RBAC, Data Masking, Row-Level Security

## ğŸ“ Project Structure

```
logistics-analytics-platform/
â”œâ”€â”€ ğŸ“„ LICENSE                                    # MIT License
â”œâ”€â”€ ğŸ“„ README.md                                  # This overview
â”œâ”€â”€ ğŸ“„ requirements.txt                           # Python dependencies
â”œâ”€â”€ ğŸ“ docs/                                      # ğŸ“š Documentation
â”‚   â”œâ”€â”€ 00_README.md                              # Complete project documentation
â”‚   â”œâ”€â”€ 01_ARCHITECTURE.md                        # Architecture and design
â”‚   â”œâ”€â”€ 02_SETUP.md                               # Setup and deployment
â”‚   â”œâ”€â”€ 03_ML_GUIDE.md                            # ML/AI engineer guide
â”‚   â”œâ”€â”€ 04_ADVANCED_FEATURES.md                   # Advanced features
â”‚   â”œâ”€â”€ 05_MONITORING.md                          # Monitoring and testing
â”‚   â”œâ”€â”€ 06_BUSINESS_IMPACT.md                     # Business value and ROI
â”‚   â”œâ”€â”€ 07_INCREMENTAL_LOADING_STRATEGY.md        # Cost optimization guide
â”‚   â”œâ”€â”€ 08_INDEX.md                               # File index with GitHub URLs
â”‚   â”œâ”€â”€ 09_DATA_DICTIONARY.md                     # Business definitions and technical specs
â”‚   â”œâ”€â”€ 10_BUSINESS_PROCESSES.md                  # Core business processes
â”‚   â”œâ”€â”€ 11_OPERATIONAL_RUNBOOKS.md                # Operational procedures
â”‚   â”œâ”€â”€ 12_TROUBLESHOOTING_GUIDES.md              # Troubleshooting procedures
â”‚   â””â”€â”€ 13_SCHEMA_MAPPING.md                      # Schema mapping and dependencies
â”œâ”€â”€ ğŸ“ dbt/                                       # dbt project (43+ models)
â”‚   â”œâ”€â”€ .sqlfluff                                 # SQL linting configuration
â”‚   â”œâ”€â”€ packages.yml                              # dbt packages configuration
â”‚   â”œâ”€â”€ models/                                   # dbt models organized by layer
â”‚   â”‚   â”œâ”€â”€ marts/                                # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics/                        # Analytics views (7 models)
â”‚   â”‚   â”‚   â”œâ”€â”€ dimensions/                       # Dimension tables (8 models)
â”‚   â”‚   â”‚   â”œâ”€â”€ facts/                           # Fact tables (5 models)
â”‚   â”‚   â”‚   â””â”€â”€ ml_features/                     # ML feature engineering (5 models)
â”‚   â”‚   â”œâ”€â”€ ml_models/                            # ML model training pipeline (2 files)
â”‚   â”‚   â”œâ”€â”€ ml_serving/                          # Real-time ML serving (2 models)
â”‚   â”‚   â”œâ”€â”€ raw/                                 # Incremental source definitions (7 models)
â”‚   â”‚   â””â”€â”€ staging/                             # Data cleaning layer (9 models)
â”‚   â”œâ”€â”€ macros/                                  # Reusable macros (8 files)
â”‚   â”œâ”€â”€ tests/                                   # Data quality tests (16+ tests)
â”‚   â””â”€â”€ snapshots/                               # Change data capture (4 models)
â”œâ”€â”€ ğŸ“ snowflake/                                # Snowflake object definitions
â”‚   â”œâ”€â”€ tables/                                  # ML-optimized table definitions
â”‚   â”‚   â”œâ”€â”€ dimensions/                          # Dimension table definitions
â”‚   â”‚   â””â”€â”€ facts/                               # Fact table definitions
â”‚   â”œâ”€â”€ views/                                   # Business intelligence views
â”‚   â”‚   â”œâ”€â”€ cost_optimization/                   # Cost optimization views
â”‚   â”‚   â””â”€â”€ monitoring/                          # Monitoring views
â”‚   â””â”€â”€ ml_objects/                              # ML-specific infrastructure
â”‚       â”œâ”€â”€ model_registry/                      # Model registry definitions
â”‚       â”œâ”€â”€ monitoring/                          # ML monitoring views
â”‚       â””â”€â”€ serving_views/                       # ML serving view definitions
â”œâ”€â”€ ğŸ“ data/                                     # Sample data generation
â”‚   â””â”€â”€ generate_sample_data.py                  # Python script for test data
â”œâ”€â”€ ğŸ“ fivetran/                                 # Fivetran monitoring and management
â”‚   â””â”€â”€ monitoring/                              # Fivetran connector monitoring (3 files)
â”œâ”€â”€ ğŸ“ scripts/                                  # Operational scripts (numbered for logical sequence)
â”‚   â”œâ”€â”€ 01_setup/                                # Infrastructure setup and configuration
â”‚   â”‚   â”œâ”€â”€ handlers/                            # Shell script handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ configure_environment.sh          # Environment configuration (dev/staging/prod)
â”‚   â”‚   â”‚   â”œâ”€â”€ execute_sql.sh                   # Parameterized SQL execution wrapper
â”‚   â”‚   â”‚   â””â”€â”€ execute_sql_python.py            # Python SQL executor with variable substitution
â”‚   â”‚   â””â”€â”€ tasks/                               # Parameterized SQL setup tasks
â”‚   â”‚       â”œâ”€â”€ 01_database_setup.sql             # Database creation (parameterized)
â”‚   â”‚       â”œâ”€â”€ 02_schema_creation.sql            # Schema creation (parameterized)
â”‚   â”‚       â”œâ”€â”€ 03_warehouse_configuration.sql    # Warehouse configuration
â”‚   â”‚       â”œâ”€â”€ 04_user_roles_permissions.sql     # Roles and permissions (parameterized)
â”‚   â”‚       â””â”€â”€ 05_resource_monitors.sql          # Resource monitors
â”‚   â”œâ”€â”€ 02_deployment/                           # Complete deployment orchestration (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL deployment tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_complete_setup.sql            # Unified setup (configurable via environment variables)
â”‚   â”‚   â”‚   â””â”€â”€ 99_verify_setup.sql              # Setup verification
â”‚   â”‚   â””â”€â”€ handlers/                            # Single deployment handler
â”‚   â”‚       â””â”€â”€ deploy_all.sh                    # Complete deployment orchestration
â”‚   â”œâ”€â”€ 03_monitoring/                           # Monitoring and quality scripts (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL monitoring tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_create_alert_tables.sql       # Alert table creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_create_monitoring_tasks.sql   # Monitoring task creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 03_setup_email_alerting.sql      # Email alerting setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 04_email_alerting_system.sql     # Email alerting configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ 05_real_time_kpis.sql            # Real-time KPI monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ 06_alert_system.sql              # Alert system setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 07_emergency_procedures.sql      # Emergency procedures
â”‚   â”‚   â”‚   â””â”€â”€ 99_verify_alert_setup.sql        # Alert system verification
â”‚   â”‚   â”œâ”€â”€ handlers/                            # Shell and Python monitoring handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ setup_alert_system.sh            # Alert system deployment script
â”‚   â”‚   â”‚   â””â”€â”€ generate_quality_report.py       # Quality report generation
â”‚   â”‚   â””â”€â”€ reports/                             # Generated monitoring reports
â”‚   â”‚       â”œâ”€â”€ quality_report.html              # HTML quality report
â”‚   â”‚       â””â”€â”€ quality_report.json              # JSON quality report
â”‚   â”œâ”€â”€ 04_performance/                          # Performance optimization scripts (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL performance tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_cost_monitoring.sql           # Cost monitoring setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_predictive_cost_optimization.sql # Predictive cost optimization
â”‚   â”‚   â”‚   â”œâ”€â”€ 03_automated_query_optimization.sql # Automated query optimization
â”‚   â”‚   â”‚   â”œâ”€â”€ 04_performance_tuning.sql        # Performance tuning procedures
â”‚   â”‚   â”‚   â”œâ”€â”€ 05_clustering_keys.sql           # Clustering key optimization
â”‚   â”‚   â”‚   â””â”€â”€ 06_automated_tasks.sql           # Automated task management
â”‚   â”‚   â””â”€â”€ handlers/                            # Shell script handlers
â”‚   â”‚       â””â”€â”€ optimize_performance.sh          # Performance optimization orchestration
â”‚   â”œâ”€â”€ 05_security/                             # Security and audit scripts (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL security tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_configure_account_audit.sql   # Account-level audit configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_create_audit_infrastructure.sql # Audit database and schema creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 03_create_audit_tables.sql       # Audit table creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 04_setup_audit_policies.sql      # Audit policy setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 05_audit_logging.sql             # Audit logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 06_data_classification.sql       # Data classification policies
â”‚   â”‚   â”‚   â”œâ”€â”€ 07_data_masking_policies.sql     # Data masking policies
â”‚   â”‚   â”‚   â”œâ”€â”€ 08_row_level_security.sql        # Row-level security setup
â”‚   â”‚   â”‚   â””â”€â”€ 99_verify_audit_setup.sql        # Audit setup verification
â”‚   â”‚   â””â”€â”€ handlers/                            # Shell security handlers
â”‚   â”‚       â””â”€â”€ setup_audit_logging.sh           # Audit logging deployment script
â”‚   â”œâ”€â”€ 06_governance/                           # Advanced data governance scripts (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL governance tasks
â”‚   â”‚   â”‚   â””â”€â”€ 01_advanced_data_lineage.sql     # Advanced data lineage setup
â”‚   â”‚   â””â”€â”€ handlers/                            # Shell governance handlers
â”‚   â”‚       â””â”€â”€ setup_governance.sh              # Governance setup orchestration
â”‚   â”œâ”€â”€ 07_streaming/                            # Stream processing scripts (Ansible-like structure)
â”‚   â”‚   â”œâ”€â”€ tasks/                               # SQL streaming tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_create_streams.sql            # Stream creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_create_monitoring_tables.sql  # Monitoring table creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 03_create_tasks.sql              # Task creation
â”‚   â”‚   â”‚   â”œâ”€â”€ 04_task_management.sql           # Task management procedures
â”‚   â”‚   â”‚   â””â”€â”€ 99_verify_deployment.sql         # Deployment verification
â”‚   â”‚   â””â”€â”€ handlers/                            # Shell streaming handlers
â”‚   â”‚       â””â”€â”€ deploy_streams_and_tasks.sh      # Stream and task deployment script
â”‚   â””â”€â”€ 08_automation/                           # Automation framework (Python scripts)
â”‚       â”œâ”€â”€ handlers/                            # Python automation handlers
â”‚       â”‚   â”œâ”€â”€ auto_deployment.py               # Automated deployment pipeline
â”‚       â”‚   â”œâ”€â”€ data_quality_monitor.py          # Data quality monitoring
â”‚       â”‚   â”œâ”€â”€ performance_optimizer.py         # Performance optimization
â”‚       â”‚   â”œâ”€â”€ ml_lifecycle_manager.py          # ML lifecycle management
â”‚       â”‚   â”œâ”€â”€ master_orchestrator.py           # Master automation orchestrator
â”‚       â”‚   â””â”€â”€ automation_dashboard.py          # Web dashboard
â”‚       â””â”€â”€ tasks/                               # Automation templates
â”‚           â””â”€â”€ templates/                       # Dashboard templates
â”‚               â””â”€â”€ automation_dashboard.html    # HTML dashboard template
â””â”€â”€ ğŸ“ .github/workflows/                        # CI/CD pipelines (5 files)
    â”œâ”€â”€ dbt_ci_cd.yml                           # Main dbt CI/CD pipeline
    â”œâ”€â”€ dbt-docs.yml                            # Documentation generation
    â”œâ”€â”€ dbt.yml                                 # dbt workflow configuration
    â”œâ”€â”€ ml_training.yml                         # ML model training pipeline
    â””â”€â”€ automation.yml                          # Automation pipeline
```

## ğŸš€ Getting Started

For detailed setup instructions, architecture overview, and comprehensive documentation, please see:

- **[Complete Documentation](docs/00_README.md)** - Full project documentation
- **[Setup Instructions](docs/02_SETUP.md)** - Complete setup and deployment guide
- **[Architecture Overview](docs/01_ARCHITECTURE.md)** - System design and technology stack
- **[ML/AI Engineer Guide](docs/03_ML_GUIDE.md)** - ML feature engineering and model development

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ Support

For questions or support, please open an issue in the GitHub repository.

---

**Built with â¤ï¸ for the data engineering and ML community**